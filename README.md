
# ğŸ§  Sentimental Data Analysis Model- Customer Feedback Analysis

This repository demonstrates a complete **Natural Language Processing (NLP)** pipeline for sentiment analysis using an **in-memory dataset**. It utilizes Python, machine learning (Logistic Regression), and text processing tools (NLTK, TF-IDF) to classify user feedback as **positive**, **neutral**, or **negative**. The project includes comprehensive **data visualizations** to provide insights into model performance and sentiment trends.

---

## ğŸ“Œ Key Features

- âœ… **Self-contained script** with no external data files â€” all feedback is stored in memory.
- ğŸ” Text preprocessing using **NLTK**: tokenization, stopword removal, and lemmatization.
- ğŸ¤– Sentiment classification with a **TF-IDF Vectorizer** and **Logistic Regression**.
- ğŸ“Š Evaluation via **accuracy**, **precision**, **recall**, **F1-score**, and **confusion matrix**.
- ğŸ“ˆ Generation of insightful visualizations:
  - Sentiment distribution (pie chart and bar chart)
  - Confusion matrix heatmap
  - Classification metrics bar chart
  - Simulated time-based sentiment trends
  - Word clouds for positive and negative feedback
- ğŸ”® Prediction functionality with confidence scores for new input texts

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ sentiment_analysis.py             # Main script with NLP pipeline and visualizations
â”œâ”€â”€ sentiment_analysis_results.png    # Sentiment breakdown and performance metrics
â”œâ”€â”€ sentiment_trend_analysis.png      # Simulated daily sentiment trends
â”œâ”€â”€ sentiment_wordclouds.png          # Word clouds for sentiment categories
â”œâ”€â”€ README.md                         # Project overview and documentation
```

---

## ğŸ“¦ Requirements

Install the required libraries using pip:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn nltk wordcloud
```

The script automatically downloads necessary NLTK resources:

```python
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
```

---

## ğŸ§  Dataset Overview

This project uses a manually curated dataset embedded directly within the Python script. Each feedback entry is labeled with a sentiment:

```python
data = {
    'feedback': [ ... ],    # List of user reviews
    'sentiment': [ ... ]    # Corresponding labels: 'positive', 'neutral', or 'negative'
}
```

---

## ğŸš€ How to Run the Project

To execute the entire pipeline and generate visualizations:

```bash
python sentiment_analysis.py
```

This will:
- Preprocess and clean the text
- Train a machine learning model
- Evaluate performance on a test split
- Generate and save visualizations
- Display sample predictions with confidence levels

---

## ğŸ“Š Model Evaluation

The model's performance is assessed using:

- **Accuracy Score**
- **Classification Report**
  - Precision, Recall, and F1-Score for each class
- **Confusion Matrix**

---

## ğŸ–¼ï¸ Visual Output Samples

### 1. Sentiment Analysis Results

- Pie and bar charts for sentiment distribution
- Confusion matrix and classification metrics

ğŸ“ Output: `sentiment_analysis_results.png`

---

### 2. Time-Based Sentiment Trends (Simulated)

- Feedback volume over time
- Positive vs. negative sentiment trends

ğŸ“ Output: `sentiment_trend_analysis.png`

---

### 3. Word Clouds

- Most frequent terms in positive and negative feedback

ğŸ“ Output: `sentiment_wordclouds.png`

---

## ğŸ§ª Sample Prediction Output

The script includes sample texts to test the trained model. Example output:

```text
Text: Terrible product. Broke within a week and the company refused to refund me.
Predicted sentiment: negative (confidence: 0.94)
```

You can modify the sample texts or call the `predict_sentiment()` function with your own inputs.

---

## ğŸ”„ Future Enhancements

- Support for sarcasm and irony detection
- Incorporation of deep learning models (e.g., LSTM, BERT)
- Real-time feedback ingestion via API or web form
- Deployment via a Streamlit or Flask web app

---

## ğŸ“„ License

You are free to use, modify, and distribute it as needed.

---

## ğŸ™ Acknowledgements

This project utilizes the following open-source libraries:

- [NLTK](https://www.nltk.org/) â€“ for natural language processing
- [Scikit-learn](https://scikit-learn.org/) â€“ for model training and evaluation
- [Matplotlib](https://matplotlib.org/) and [Seaborn](https://seaborn.pydata.org/) â€“ for data visualization
- [WordCloud](https://github.com/amueller/word_cloud) â€“ for visualizing common terms

---

> Crafted with ğŸ’¡ and ğŸ’¬ for data scientists, developers, and NLP enthusiasts.

---

